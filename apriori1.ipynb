{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import chain, combinations\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare(corpus):\n",
    "    f = open(corpus)\n",
    "    lines = f.read().splitlines()\n",
    "    summary = {}\n",
    "    ind = 1\n",
    "    stop = set(stopwords.words('english'))\n",
    "    for line in lines:\n",
    "        line = re.sub(r\"http\\S+\", \"\", line)    \n",
    "        line = re.sub(' +',' ',line)\n",
    "        tokenized_sent =word_tokenize(line)\n",
    "        list_of_words = [i.lower() for i in tokenized_sent if i.lower() not in stop]\n",
    "        tw = []\n",
    "        for w in list_of_words:\n",
    "            if w not in ['.',',','#','earthquake','nepal','nepalearthquake'] and w not in tw:\n",
    "                tw.append(w)\n",
    "        yield tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def itemset_from_data(data):\n",
    "    itemset = set()\n",
    "    transaction_list = list()\n",
    "    for row in data:\n",
    "        transaction_list.append(frozenset(row))\n",
    "        for item in row:\n",
    "            if item:\n",
    "                itemset.add(frozenset([item]))\n",
    "    return itemset, transaction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def joinset(itemset, k):\n",
    "    return set([i.union(j) for i in itemset for j in itemset if len(i.union(j)) == k])\n",
    "\n",
    "\n",
    "def subsets(itemset):\n",
    "    return chain(*[combinations(itemset, i + 1) for i, a in enumerate(itemset)])\n",
    "    \n",
    "\n",
    "def itemset_support(transaction_list, itemset, min_support=0):\n",
    "    len_transaction_list = len(transaction_list)\n",
    "    l = [\n",
    "        (item, float(sum(1 for row in transaction_list if item.issubset(row)))/len_transaction_list) \n",
    "        for item in itemset\n",
    "    ]\n",
    "    return dict([(item, support) for item, support in l if support >= min_support])\n",
    "\n",
    "\n",
    "def freq_itemset(transaction_list, c_itemset, min_support):\n",
    "    f_itemset = dict()\n",
    "\n",
    "    k = 1\n",
    "    while True:\n",
    "        if k > 1:\n",
    "            c_itemset = joinset(l_itemset, k)\n",
    "        l_itemset = itemset_support(transaction_list, c_itemset, min_support)\n",
    "        if not l_itemset:\n",
    "            break\n",
    "        f_itemset.update(l_itemset)\n",
    "        k += 1\n",
    "\n",
    "    return f_itemset    \n",
    "\n",
    "\n",
    "def apriori(itemset, transaction_list, min_support, min_confidence):\n",
    "    # Get first itemset and transactions\n",
    "    #itemset, transaction_list = itemset_from_data(data)\n",
    "\n",
    "    # Get the frequent itemset\n",
    "    f_itemset = freq_itemset(transaction_list, itemset, min_support)\n",
    "\n",
    "    # Association rules\n",
    "    rules = list()\n",
    "    for item, support in f_itemset.items():\n",
    "        if len(item) > 1:\n",
    "            for A in subsets(item):\n",
    "                B = item.difference(A)\n",
    "                if B:\n",
    "                    A = frozenset(A)\n",
    "                    AB = A | B\n",
    "                    confidence = float(f_itemset[AB]) / f_itemset[A]\n",
    "                    if confidence >= min_confidence:\n",
    "                        rules.append((A, B, confidence))    \n",
    "    return rules, f_itemset\n",
    "\n",
    "\n",
    "def print_report(rules, f_itemset):\n",
    "    print('--Frequent Itemset--')\n",
    "    for item, support in sorted(f_itemset.items(), key=lambda (item, support): support):\n",
    "        print('[I] {} : {}'.format(tuple(item), round(support, 4)))\n",
    "\n",
    "    print('')\n",
    "    print('--Rules--')\n",
    "    for A, B, confidence in sorted(rules, key=lambda (A, B, confidence): confidence):\n",
    "        print('[R] {} => {} : {}'.format(tuple(A), tuple(B), round(confidence, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = prepare(\"output.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "itemset, transaction_list = itemset_from_data(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rules, itemset = apriori(itemset, transaction_list, 0.005, 0.40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(frozenset({'affected'}), frozenset({'thoughts'}), 0.23689320388349513),\n",
       " (frozenset({'thoughts'}), frozenset({'affected'}), 0.24646464646464647),\n",
       " (frozenset({'avalanche'}), frozenset({'everest'}), 0.8278145695364238),\n",
       " (frozenset({'everest'}), frozenset({'avalanche'}), 0.38819875776397517),\n",
       " (frozenset({'safe'}), frozenset({'stay'}), 0.23324396782841822),\n",
       " (frozenset({'stay'}), frozenset({'safe'}), 0.5576923076923077),\n",
       " (frozenset({'!'}), frozenset({'prayers'}), 0.13145539906103287),\n",
       " (frozenset({'go'}), frozenset({'prayers'}), 0.49246231155778897),\n",
       " (frozenset({'prayers'}), frozenset({'go'}), 0.10816777041942605),\n",
       " (frozenset({'bless'}), frozenset({'god'}), 0.803921568627451),\n",
       " (frozenset({'god'}), frozenset({'bless'}), 0.24848484848484848),\n",
       " (frozenset({'death'}), frozenset({'rises', 'toll'}), 0.21645021645021645),\n",
       " (frozenset({'rises'}), frozenset({'death', 'toll'}), 0.9090909090909091),\n",
       " (frozenset({'toll'}), frozenset({'death', 'rises'}), 0.21367521367521367),\n",
       " (frozenset({'death', 'rises'}), frozenset({'toll'}), 0.9615384615384616),\n",
       " (frozenset({'death', 'toll'}), frozenset({'rises'}), 0.2347417840375587),\n",
       " (frozenset({'rises', 'toll'}), frozenset({'death'}), 0.9803921568627451),\n",
       " (frozenset({'everyone'}), frozenset({'prayers'}), 0.31851851851851853),\n",
       " (frozenset({'heart'}), frozenset({'goes'}), 0.5668449197860963),\n",
       " (frozenset({'goes'}), frozenset({'heart'}), 0.803030303030303),\n",
       " (frozenset({'control'}), frozenset({'room'}), 0.8936170212765957),\n",
       " (frozenset({'room'}), frozenset({'control'}), 0.9130434782608695),\n",
       " (frozenset({'7.9'}), frozenset({'magnitude'}), 0.3656716417910448),\n",
       " (frozenset({'magnitude'}), frozenset({'7.9'}), 0.550561797752809),\n",
       " (frozenset({'numbers'}), frozenset({'emergency'}), 0.5148936170212766),\n",
       " (frozenset({'emergency'}), frozenset({'numbers'}), 0.5426008968609866),\n",
       " (frozenset({'thoughts'}), frozenset({'people'}), 0.298989898989899),\n",
       " (frozenset({'people'}), frozenset({'thoughts'}), 0.132973944294699),\n",
       " (frozenset({'prayers'}), frozenset({'people'}), 0.2682119205298013),\n",
       " (frozenset({'people'}), frozenset({'prayers'}), 0.2183288409703504),\n",
       " (frozenset({'death'}), frozenset({'rises'}), 0.22510822510822512),\n",
       " (frozenset({'rises'}), frozenset({'death'}), 0.9454545454545454),\n",
       " (frozenset({'death'}), frozenset({'toll'}), 0.922077922077922),\n",
       " (frozenset({'toll'}), frozenset({'death'}), 0.9102564102564102),\n",
       " (frozenset({'safe'}), frozenset({'hope'}), 0.2868632707774799),\n",
       " (frozenset({'hope'}), frozenset({'safe'}), 0.311046511627907),\n",
       " (frozenset({'may'}), frozenset({'god'}), 0.3715170278637771),\n",
       " (frozenset({'god'}), frozenset({'may'}), 0.36363636363636365),\n",
       " (frozenset({'&'}), frozenset({'prayers'}), 0.16390423572744015),\n",
       " (frozenset({'affected'}), frozenset({'people'}), 0.22135922330097088),\n",
       " (frozenset({'people'}), frozenset({'affected'}), 0.10242587601078167),\n",
       " (frozenset({'('}), frozenset({':'}), 0.9224806201550387),\n",
       " (frozenset({':'}), frozenset({'('}), 0.7300613496932515),\n",
       " (frozenset({'rises'}), frozenset({'toll'}), 0.9272727272727272),\n",
       " (frozenset({'toll'}), frozenset({'rises'}), 0.21794871794871795),\n",
       " (frozenset({'!'}), frozenset({'people'}), 0.15179968701095461),\n",
       " (frozenset({'thoughts'}), frozenset({'prayers'}), 0.5292929292929293),\n",
       " (frozenset({'prayers'}), frozenset({'thoughts'}), 0.2891832229580574),\n",
       " (frozenset({'victims'}), frozenset({'prayers'}), 0.31785714285714284),\n",
       " (frozenset({'embassy'}), frozenset({'indian'}), 0.8817204301075269),\n",
       " (frozenset({'indian'}), frozenset({'embassy'}), 0.328),\n",
       " (frozenset({'affected'}), frozenset({'prayers'}), 0.4116504854368932),\n",
       " (frozenset({'prayers'}), frozenset({'affected'}), 0.23399558498896247)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules\n",
    "#itemset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
